INFO - 01/18/26 00:31:35 - 0:00:00 - ============ Initialized logger ============
INFO - 01/18/26 00:31:35 - 0:00:00 - activation: ReLU
                                     atom_messages: False
                                     batch_size: 32
                                     bias: False
                                     checkpoint_dir: None
                                     checkpoint_path: ./dumped/pretrained_graph_encoder/original_CMPN_0623_1350_14000th_epoch.pkl
                                     checkpoint_paths: ['./dumped/pretrained_graph_encoder/original_CMPN_0623_1350_14000th_epoch.pkl']
                                     command: python train_kapt.py --data_path 'data\bbbp.csv' --dataset_type classification --epochs 50 --batch_size 32 --init_lr '1e-4' --gpu 0 --save_model_path 'checkpoints\kapt_bbbp_best.pt' --exp_name kapt_bbbp --exp_id bbbp_051 --step functional_prompt --split_type scaffold_balanced --metric auc --seed 51 --checkpoint_path './dumped/pretrained_graph_encoder/original_CMPN_0623_1350_14000th_epoch.pkl' --exp_id "bbbp_051"
                                     config_path: None
                                     crossval_index_dir: None
                                     crossval_index_file: None
                                     cuda: True
                                     data_path: data\bbbp.csv
                                     dataset_type: classification
                                     depth: 3
                                     dropout: 0.0
                                     dump_path: dumped
                                     encoder_name: CMPNN
                                     ensemble_size: 1
                                     epochs: 50
                                     exp_id: bbbp_051
                                     exp_name: kapt_bbbp
                                     features_generator: None
                                     features_only: False
                                     features_path: None
                                     features_scaling: True
                                     ffn_hidden_size: 300
                                     ffn_num_layers: 2
                                     final_lr: 0.0001
                                     folds_file: None
                                     gpu: 0
                                     hidden_size: 300
                                     init_lr: 0.0001
                                     log_frequency: 10
                                     max_data_size: None
                                     max_lr: 0.001
                                     metric: auc
                                     minimize_score: False
                                     multiclass_num_classes: 3
                                     no_cache: False
                                     num_lrs: 1
                                     num_runs: 1
                                     quiet: False
                                     save_dir: ./ckpt
                                     save_model_path: checkpoints\kapt_bbbp_best.pt
                                     save_smiles_splits: False
                                     seed: 51
                                     separate_test_features_path: None
                                     separate_test_path: None
                                     separate_val_features_path: None
                                     separate_val_path: None
                                     show_individual_scores: False
                                     split_sizes: [0.8, 0.1, 0.1]
                                     split_type: scaffold_balanced
                                     step: functional_prompt
                                     task_id: 0
                                     temperature: 0.1
                                     test: False
                                     test_fold_index: None
                                     undirected: False
                                     use_compound_names: False
                                     use_input_features: None
                                     use_kapt: True
                                     val_fold_index: None
                                     warmup_epochs: 2.0
INFO - 01/18/26 00:31:35 - 0:00:00 - ========================
                                     # Git Version: unknown #
                                     ========================
INFO - 01/18/26 00:31:35 - 0:00:00 - The experiment will be stored in dumped\0118-kapt_bbbp\bbbp_051
                                     
INFO - 01/18/26 00:31:35 - 0:00:00 - Running command: python train_kapt.py --data_path 'data\bbbp.csv' --dataset_type classification --epochs 50 --batch_size 32 --init_lr '1e-4' --gpu 0 --save_model_path 'checkpoints\kapt_bbbp_best.pt' --exp_name kapt_bbbp --exp_id bbbp_051 --step functional_prompt --split_type scaffold_balanced --metric auc --seed 51 --checkpoint_path './dumped/pretrained_graph_encoder/original_CMPN_0623_1350_14000th_epoch.pkl'

INFO - 01/18/26 00:31:35 - 0:00:00 - Using GPU: 0
INFO - 01/18/26 00:31:35 - 0:00:00 - Initialized KAPT Training | GPU: 0 | Epochs: 50 | Batch Size: 32
INFO - 01/18/26 00:31:35 - 0:00:00 - KAPT Training | Task ID: 0 | Step: functional_prompt
INFO - 01/18/26 00:31:35 - 0:00:00 - ===== Run 1/1 (Seed: 51) =====
INFO - 01/18/26 00:31:35 - 0:00:00 - Loading data
INFO - 01/18/26 00:31:35 - 0:00:00 - Number of tasks = 1
DEBUG - 01/18/26 00:31:35 - 0:00:00 - Splitting data with seed 51
DEBUG - 01/18/26 00:31:36 - 0:00:01 - Total scaffolds = 1,025 | train scaffolds = 866 | val scaffolds = 57 | test scaffolds = 102
DEBUG - 01/18/26 00:31:36 - 0:00:01 - Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels: [(array([0.72992701]), array([137], dtype=int64)), (array([0.]), array([1], dtype=int64)), (array([0.]), array([1], dtype=int64)), (array([0.]), array([1], dtype=int64)), (array([1.]), array([2], dtype=int64)), (array([1.]), array([1], dtype=int64)), (array([1.]), array([1], dtype=int64)), (array([0.5]), array([2], dtype=int64)), (array([1.]), array([1], dtype=int64)), (array([1.]), array([1], dtype=int64))]
DEBUG - 01/18/26 00:31:36 - 0:00:01 - Class sizes
DEBUG - 01/18/26 00:31:36 - 0:00:01 - p_np 0: 23.49%, 1: 76.51%
DEBUG - 01/18/26 00:31:36 - 0:00:01 - Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
DEBUG - 01/18/26 00:31:36 - 0:00:01 - Loading model from ./dumped/pretrained_graph_encoder/original_CMPN_0623_1350_14000th_epoch.pkl
DEBUG - 01/18/26 00:31:36 - 0:00:01 - MoleculeModel(
                                        (sigmoid): Sigmoid()
                                        (encoder): CMPN(
                                          (encoder): CMPNEncoder(
                                            (dropout_layer): Dropout(p=0.0, inplace=False)
                                            (act_func): ReLU()
                                            (W_i_atom): PromptGeneratorOutput(
                                              (self_out): Linear(in_features=133, out_features=300, bias=False)
                                              (prompt_generator): Prompt_generator(
                                                (linear): Linear(in_features=133, out_features=300, bias=True)
                                                (attention_layer_1): AttentionLayer(
                                                  (w_q): Linear(in_features=133, out_features=32, bias=True)
                                                  (w_k): Linear(in_features=133, out_features=32, bias=True)
                                                  (w_v): Linear(in_features=133, out_features=32, bias=True)
                                                  (dense): Linear(in_features=32, out_features=133, bias=True)
                                                  (LayerNorm): LayerNorm((133,), eps=1e-06, elementwise_affine=True)
                                                  (dropout): Dropout(p=0.1, inplace=False)
                                                )
                                                (attention_layer_2): AttentionLayer(
                                                  (w_q): Linear(in_features=133, out_features=32, bias=True)
                                                  (w_k): Linear(in_features=133, out_features=32, bias=True)
                                                  (w_v): Linear(in_features=133, out_features=32, bias=True)
                                                  (dense): Linear(in_features=32, out_features=133, bias=True)
                                                  (LayerNorm): LayerNorm((133,), eps=1e-06, elementwise_affine=True)
                                                  (dropout): Dropout(p=0.1, inplace=False)
                                                )
                                                (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
                                              )
                                            )
                                            (W_i_bond): Linear(in_features=147, out_features=300, bias=False)
                                            (W_h_atom): Linear(in_features=447, out_features=300, bias=False)
                                            (W_h_0): Linear(in_features=300, out_features=300, bias=False)
                                            (W_h_1): Linear(in_features=300, out_features=300, bias=False)
                                            (W_o): Linear(in_features=600, out_features=300, bias=True)
                                            (gru): BatchGRU(
                                              (gru): GRU(300, 300, batch_first=True, bidirectional=True)
                                            )
                                            (lr): Linear(in_features=900, out_features=300, bias=False)
                                            (W_i_atom_new): Linear(in_features=266, out_features=300, bias=False)
                                          )
                                        )
                                        (ffn): Sequential(
                                          (0): Dropout(p=0.0, inplace=False)
                                          (1): Linear(in_features=300, out_features=300, bias=True)
                                          (2): ReLU()
                                          (3): Dropout(p=0.0, inplace=False)
                                          (4): Linear(in_features=300, out_features=1, bias=True)
                                        )
                                      )
DEBUG - 01/18/26 00:31:36 - 0:00:01 - Number of parameters = 2,178,806
DEBUG - 01/18/26 00:31:36 - 0:00:01 - Moving model to cuda
